{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HglivuILDms6"
      },
      "source": [
        "# About Mask Language Model - Task 1 - QP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3kI-rlg0QbZ"
      },
      "source": [
        "### Library and Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsEZInQAscco"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries and modules for natural language processing and machine learning tasks\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "from transformers import TrainingArguments, Trainer, pipeline\n",
        "from transformers import RobertaForMaskedLM, RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from transformers import AdamW\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXARPJsULeO9"
      },
      "outputs": [],
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 6\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfkyiY_mwOgF"
      },
      "source": [
        "## Classification QP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyYCbDCxwSAR",
        "outputId": "bfff59b3-def1-48b1-d198-8bfe1089f7d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting RUST\n",
            "  Downloading RUST-1.3.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m580.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysam (from RUST)\n",
            "  Downloading pysam-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl (21.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.9/21.9 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from RUST) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from RUST) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RUST) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RUST) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RUST) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RUST) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RUST) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RUST) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RUST) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RUST) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->RUST) (1.16.0)\n",
            "Installing collected packages: pysam, RUST\n",
            "Successfully installed RUST-1.3.1 pysam-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install RUST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXF6ILi8DVlH"
      },
      "outputs": [],
      "source": [
        "# Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9Iov4laDmG9"
      },
      "outputs": [],
      "source": [
        "# Load data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load and preprocess training dataset from the JSON file\n",
        "with open('drive/MyDrive/1.DATA/QP/Numeracy600K_headline_train.json', 'r') as file:\n",
        "    training_data = json.load(file)\n",
        "    training_df = pd.DataFrame(training_data)\n",
        "\n",
        "# Load and preprocess validation dataset from another JSON file\n",
        "with open('drive/MyDrive/1.DATA/QP/Numeracy600K_headline_test.json', 'r') as file:\n",
        "    validation_data = json.load(file)\n",
        "    validation_df = pd.DataFrame(validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GVSM_04Dpqi"
      },
      "outputs": [],
      "source": [
        "# Checking unique values in the 'magnitude' column of the training dataframe\n",
        "training_df['magnitude'].unique()\n",
        "\n",
        "# Displaying descriptive statistics to analyze the distribution\n",
        "training_df.describe()\n",
        "\n",
        "# Inspecting the values of the first row in the training dataframe for initial data exploration\n",
        "training_df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dsR8gZREKE4"
      },
      "outputs": [],
      "source": [
        "class MagnitudeData(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        \"\"\"\n",
        "        Custom PyTorch Dataset class for processing data with text and magnitude labels.\n",
        "\n",
        "        Args:\n",
        "        - dataframe: Pandas DataFrame containing 'title' (text data) and 'magnitude' columns\n",
        "        - tokenizer: Tokenizer object for encoding text inputs\n",
        "        - max_len: Maximum length of tokenized sequences\n",
        "\n",
        "        Initializes the dataset with necessary attributes.\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = self.data.title\n",
        "        self.targets = self.data.magnitude\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Defines the length of the dataset.\n",
        "\n",
        "        Returns:\n",
        "        - Length of the text data\n",
        "        \"\"\"\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Retrieves a single data sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "        - index: Index to retrieve the data sample\n",
        "\n",
        "        Returns:\n",
        "        - Dictionary containing tokenized inputs and targets as PyTorch tensors\n",
        "        \"\"\"\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        # Tokenizing the text input\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        # Constructing and returning the processed data sample\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWkKIajf4YUa"
      },
      "outputs": [],
      "source": [
        "# Splits the dataset into training and testing sets based on a specified ratio,\n",
        "# then creates instances of the MagnitudeData class for both sets using a tokenizer and maximum length.\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)\n",
        "\n",
        "train_size = 0.3\n",
        "train_data=training_df.sample(frac=train_size,random_state=200)\n",
        "test_data=training_df.drop(train_data.index).reset_index(drop=True)\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(training_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
        "\n",
        "training_set = MagnitudeData(train_data, tokenizer, MAX_LEN)\n",
        "testing_set = MagnitudeData(test_data, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbnyoFNs4mv3"
      },
      "outputs": [],
      "source": [
        "# Configures data loaders for training and testing using DataLoader from PyTorch,\n",
        "# with specified batch sizes and settings for shuffling and workers.\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7lQkDWd5Ydt"
      },
      "outputs": [],
      "source": [
        "class RobertaClass(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        \"\"\"\n",
        "        Initializes the RobertaClass module.\n",
        "\n",
        "        Args:\n",
        "        - model: Pre-trained RoBERTa model\n",
        "\n",
        "        Initializes the layers and components needed for the custom classification model.\n",
        "        \"\"\"\n",
        "        super(RobertaClass, self).__init__()\n",
        "        self.l1 = model  # Initializing the base pre-trained RoBERTa model\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)  # Adding a linear layer for feature transformation\n",
        "        self.dropout = torch.nn.Dropout(0.3)  # Adding dropout layer for regularization\n",
        "        self.classifier = torch.nn.Linear(768, 8)  # Adding a linear layer for final classification\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        \"\"\"\n",
        "        Defines the forward pass through the model architecture.\n",
        "\n",
        "        Args:\n",
        "        - input_ids: Tokenized input IDs\n",
        "        - attention_mask: Attention mask for handling padding tokens\n",
        "        - token_type_ids: Token type IDs for sequence classification\n",
        "\n",
        "        Returns:\n",
        "        - Output logits for classification\n",
        "        \"\"\"\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        hidden_state = output_1[0]  # Extracts the hidden state from RoBERTa's output\n",
        "        pooler = hidden_state[:, 0]  # Extracts the pooled output (CLS token)\n",
        "        pooler = self.pre_classifier(pooler)  # Passes the pooled output through the linear layer\n",
        "        pooler = torch.nn.ReLU()(pooler)  # Applies ReLU activation function\n",
        "        pooler = self.dropout(pooler)  # Applies dropout for regularization\n",
        "        output = self.classifier(pooler)  # Final classification through linear layer\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8sEmOP31olJ"
      },
      "outputs": [],
      "source": [
        "# Add new mask for [Num]\n",
        "\n",
        "# Define a dictionary containing a special token '[Num]' to be added as a mask token\n",
        "special_tokens_dict = {'mask_token': '[Num]'}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Resize the token embeddings in the RoBERTa model to accommodate the added tokens\n",
        "roberta.resize_token_embeddings(len(tokenizer))\n",
        "model = RobertaClass(roberta)\n",
        "model.to(device)\n",
        "\n",
        "# Print the newly added mask token (should display '[Num]')\n",
        "print(tokenizer.mask_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DZrYGXr65kE4"
      },
      "outputs": [],
      "source": [
        "# Creating the loss function and optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pt0O5KkC6NYr"
      },
      "outputs": [],
      "source": [
        "def calcuate_accuracy(preds, targets):\n",
        "    n_correct = (preds==targets).sum().item()\n",
        "    return n_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PtcZNmMP-Skh"
      },
      "outputs": [],
      "source": [
        "# Defining the training function on 80% of the dataset to tune the DistilBERT model\n",
        "def train(epoch):\n",
        "    tr_loss = 0  # Initializing training loss\n",
        "    n_correct = 0  # Initializing the number of correct predictions\n",
        "    nb_tr_steps = 0  # Counting the number of training steps\n",
        "    nb_tr_examples = 0  # Counting the number of training examples\n",
        "    model.train()  # Setting the model to train mode\n",
        "\n",
        "    # Iterating over the training_loader (data loader containing training samples)\n",
        "    for _, data in tqdm(enumerate(training_loader, 0)):\n",
        "        # Extracting inputs and targets from the training data\n",
        "        ids = data['ids'].to(device, dtype=torch.long)\n",
        "        mask = data['mask'].to(device, dtype=torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "        targets = data['targets'].to(device, dtype=torch.long)\n",
        "\n",
        "        # Forward pass through the model to obtain predictions\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        # Calculating the loss between predicted outputs and actual targets\n",
        "        loss = loss_function(outputs, targets)\n",
        "        tr_loss += loss.item()  # Accumulating the total training loss\n",
        "\n",
        "        # Calculating accuracy for the batch\n",
        "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += calcuate_accuracy(big_idx, targets)\n",
        "\n",
        "        nb_tr_steps += 1  # Incrementing the number of training steps\n",
        "        nb_tr_examples += targets.size(0)  # Accumulating the total number of training examples processed\n",
        "\n",
        "        # Displaying training metrics at certain intervals (every 5000 steps in this case)\n",
        "        if _ % 5000 == 0:\n",
        "            loss_step = tr_loss / nb_tr_steps\n",
        "            accu_step = (n_correct * 100) / nb_tr_examples\n",
        "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
        "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
        "\n",
        "        optimizer.zero_grad()  # Zeroing out gradients to avoid accumulation\n",
        "        loss.backward()  # Backpropagation: computing gradients\n",
        "        optimizer.step()  # Optimizer step: updating weights based on gradients\n",
        "\n",
        "        # Breaking the loop after a certain number of steps (for demonstration purposes)\n",
        "        if _ == 15000:\n",
        "            break\n",
        "\n",
        "    # Displaying overall accuracy and loss for the epoch\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}')\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    epoch_accu = (n_correct * 100) / nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return  # Returning from the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VV6OzMSr-XG6"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1\n",
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1Q11-Ygw-b-u"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    model.eval()  # Sets the model to evaluation mode\n",
        "    n_correct = 0\n",
        "    n_wrong = 0\n",
        "    total = 0\n",
        "    tr_loss = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "\n",
        "    # Disables gradient calculation for evaluation\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
        "            ids = data['ids'].to(device, dtype=torch.long)\n",
        "            mask = data['mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype=torch.long)\n",
        "\n",
        "            # Obtains model predictions for the input data\n",
        "            outputs = model(ids, mask, token_type_ids).squeeze()\n",
        "\n",
        "            # Calculates the loss between predictions and actual targets\n",
        "            loss = loss_function(outputs, targets)\n",
        "            tr_loss += loss.item()  # Accumulating validation loss\n",
        "\n",
        "            # Calculating accuracy for the batch\n",
        "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "            n_correct += calcuate_accuracy(big_idx, targets)\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples += targets.size(0)\n",
        "\n",
        "            # Displaying validation metrics at certain intervals (every 5000 steps in this case)\n",
        "            if _ % 5000 == 0:\n",
        "                loss_step = tr_loss / nb_tr_steps\n",
        "                accu_step = (n_correct * 100) / nb_tr_examples\n",
        "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
        "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
        "                break  # Breaking the loop for demonstration\n",
        "\n",
        "    # Calculating and displaying overall validation accuracy and loss for the epoch\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    epoch_accu = (n_correct * 100) / nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return epoch_accu  # Returning the epoch-level accuracy for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B4AppdL9-dwn"
      },
      "outputs": [],
      "source": [
        "acc = valid(model, testing_loader)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kRT3L6_J-fOL"
      },
      "outputs": [],
      "source": [
        "output_model_file = 'pytorch_roberta_sentiment.bin'\n",
        "output_vocab_file = './'\n",
        "\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "tokenizer.save_vocabulary(output_vocab_file)\n",
        "\n",
        "print('All files saved')\n",
        "print('This tutorial is completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z3hCpRpLRI7"
      },
      "source": [
        "## Inference QP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KdqUBf6o-nl",
        "outputId": "8813528f-5f2a-43ab-c541-253e7befedca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPn-AIedorl2"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess training dataset from the JSON file\n",
        "with open('drive/MyDrive/1.DATA/QP/Numeracy600K_headline_train.json', 'r') as file:\n",
        "    training_data = json.load(file)\n",
        "    training_df = pd.DataFrame(training_data)\n",
        "\n",
        "# Load and preprocess validation dataset from another JSON file\n",
        "with open('drive/MyDrive/1.DATA/QP/Numeracy600K_headline_test.json', 'r') as file:\n",
        "    validation_data = json.load(file)\n",
        "    validation_df = pd.DataFrame(validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g3N1OiTESOV"
      },
      "outputs": [],
      "source": [
        "# Create model dictionary\n",
        "test_models = {\n",
        "                'BERT': 'bert-base-uncased', # 0.068\n",
        "                'RoBERTa': 'roberta-base', # 0.184\n",
        "                'MathBERT': 'tbs17/MathBERT-custom', # 0.008\n",
        "                'LinkBERT': 'michiyasunaga/LinkBERT-base', # 0.001\n",
        "                'FinBERT': 'ProsusAI/finbert', # 0.001\n",
        "                'ALBERT': 'albert-base-v2', # 0.132\n",
        "                # 'Xlnet': 'xlnet-base-cased',\n",
        "               }\n",
        "\n",
        "def get_model(model_name='BERT',new_mask_word='[Num]'):\n",
        "  if model_name not in test_models:\n",
        "    model_name = 'BERT'\n",
        "  tokenizer = AutoTokenizer.from_pretrained(test_models[model_name])\n",
        "  model = AutoModelForMaskedLM.from_pretrained(test_models[model_name])\n",
        "\n",
        "  # Add a new mask word/token\n",
        "  tokenizer.add_special_tokens({'mask_token': new_mask_word})\n",
        "  model.resize_token_embeddings(len(tokenizer))\n",
        "  print(f\"Is [Num] a Mask Token: {new_mask_word in tokenizer.get_vocab()}\")\n",
        "\n",
        "  return tokenizer, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wADulc6GdQsB",
        "outputId": "45179665-e240-429f-b505-dfd3c77ded7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On the scene: Son Jung Wan Spring [Num] presentation \t 4 \t On the scene: Son Jung Wan Spring 2014 presentation\n",
            "Oceania Cruises sending R-Class for $[Num] million refurbishment \t 2 \t Oceania Cruises sending R-Class for $50 million refurbishment\n",
            "Seahawks at or near the top of many Week [Num] Power Rankings \t 1 \t Seahawks at or near the top of many Week 4 Power Rankings\n",
            "Mega Millions winning numbers drawn: Did anyone win the lottery jackpot May [Num]? \t 2 \t Mega Millions winning numbers drawn: Did anyone win the lottery jackpot May 14?\n",
            "Girl Scouts have fun at Geocaching [Num] \t 3 \t Girl Scouts have fun at Geocaching 101\n",
            "Photographing [Num]th fireworks from Cabrillo National Monument \t 1 \t Photographing 4th fireworks from Cabrillo National Monument\n",
            "Kris Kross Chris Kelly dies at age [Num] \t 2 \t Kris Kross Chris Kelly dies at age 34\n",
            "ROH news: Main event of 'Final Battle [Num]' announced \t 4 \t ROH news: Main event of 'Final Battle 2013' announced\n",
            "Indie Music Mondays: August 5th, [Num] - Open Roads, Open Minds Playlist \t 4 \t Indie Music Mondays: August 5th, 2013 - Open Roads, Open Minds Playlist\n",
            "Lapham Peak Colorama Run-Walk takes off October [Num] \t 1 \t Lapham Peak Colorama Run-Walk takes off October 5\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random_items = random.sample(validation_data, 10)\n",
        "for item in random_items:\n",
        "  print(item['masked'], '\\t', item['magnitude'], '\\t', item['title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf8Tha5gPcli"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import math\n",
        "import statistics\n",
        "\n",
        "def get_f1m(tokenizer, model, data):\n",
        "    # Create a pipeline for filling masked tokens using the provided model and tokenizer\n",
        "    fill_mask = pipeline(\n",
        "        \"fill-mask\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    # Initialize lists to store ground truth and predicted magnitudes\n",
        "    true_magnitudes = []\n",
        "    predicted_magnitudes = []\n",
        "\n",
        "    # Calculate predicted magnitudes and collect true magnitudes\n",
        "    for sample in data[:10]:\n",
        "        text = sample[\"masked\"]\n",
        "        ground_truth = sample[\"magnitude\"]  # Ground truth numerical magnitude\n",
        "\n",
        "        # Tokenize and mask the input text\n",
        "        tokenized_input = tokenizer(text, return_tensors=\"pt\")\n",
        "        mask_token_index = torch.where(tokenized_input[\"input_ids\"] == tokenizer.mask_token_id)\n",
        "\n",
        "        # Model inference for masked token prediction\n",
        "        predictions = fill_mask(text)\n",
        "        predicted_magnitudes.append(ground_truth)\n",
        "        print(predictions[0]['token_str'], 'gt:', ground_truth)\n",
        "\n",
        "        try:  # Check if the number of predicted tokens is not one\n",
        "            predicted_token = predictions[0][\"token_str\"]\n",
        "        except:\n",
        "            predicted_tokens = [item['token_str'] for item in predictions[0]]\n",
        "            predicted_token = statistics.mode(predicted_tokens)\n",
        "\n",
        "        try:  # Check if the predicted token is a number\n",
        "            predicted_magnitude = math.floor(math.log10(float(predicted_token)))  # Convert predicted token to float\n",
        "            try:\n",
        "                predicted_magnitude += 1\n",
        "                if predicted_magnitude > 6:\n",
        "                    predicted_magnitude = 6\n",
        "                true_magnitudes.append(predicted_magnitude)\n",
        "            except:\n",
        "                true_magnitudes.append(0)\n",
        "        except ValueError as e:\n",
        "            true_magnitudes.append(0)\n",
        "\n",
        "    # Calculate the F1 score based on predicted and true magnitudes\n",
        "    macro_f1 = f1_score(true_magnitudes, predicted_magnitudes, average='macro')\n",
        "    print(f\"Macro F1 score based on predicted magnitudes: {macro_f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctECLnnFvE2V"
      },
      "outputs": [],
      "source": [
        "# Iterate through each model name in the 'test_models' list\n",
        "for model_name in test_models:\n",
        "    print(model_name, ': ')  # Print the current model name\n",
        "\n",
        "    # Get the tokenizer and model corresponding to the current model name\n",
        "    tokenizer, model = get_model(model_name)\n",
        "\n",
        "    num_groups = 300  # Define the number of groups to create\n",
        "\n",
        "    random_groups = []  # Initialize an empty list to store randomly split groups of data\n",
        "\n",
        "    # Create 'num_groups' random groups by splitting the 'validation_data'\n",
        "    for _ in range(num_groups):\n",
        "        _, group = train_test_split(validation_data, test_size=0.2, random_state=np.random.randint(100))\n",
        "        random_groups.append(group)\n",
        "\n",
        "    # Access each randomly created group for evaluation\n",
        "    for i, group in enumerate(random_groups):\n",
        "        # Evaluate the F1 score for the current tokenizer, model, and each random group\n",
        "        get_f1m(tokenizer, model, random_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUO9QtOvkXMs"
      },
      "source": [
        "## Inference QQA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIeAmII-lJtj"
      },
      "source": [
        "Code Reference: https://github.com/allenai/numglue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPAZmZSYkiWO",
        "outputId": "035a88e7-65d2-4d46-96cb-8f50611508bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Load data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load and preprocess training dataset from the JSON file\n",
        "with open('drive/MyDrive/1.DATA/QQA/QQA_train.json', 'r') as file:\n",
        "    training_data = json.load(file)\n",
        "    training_df = pd.DataFrame(training_data)\n",
        "\n",
        "# Load and preprocess validation dataset from another JSON file\n",
        "with open('drive/MyDrive/1.DATA/QQA/QQA_dev.json', 'r') as file:\n",
        "    validation_data = json.load(file)\n",
        "    validation_df = pd.DataFrame(validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7VPrh857PU0",
        "outputId": "24bf8607-ddc6-4439-b52e-4a53ac59fd4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            question     Option1      Option2  \\\n",
            "0  The ranger and the rustler both were riding ho...  the ranger  the rustler   \n",
            "\n",
            "     answer    type                                   question_sci_10E  \\\n",
            "0  Option 2  Type_3  The ranger and the rustler both were riding ho...   \n",
            "\n",
            "                                       question_char  \\\n",
            "0  The ranger and the rustler both were riding ho...   \n",
            "\n",
            "                               question_sci_10E_char  \\\n",
            "0  The ranger and the rustler both were riding ho...   \n",
            "\n",
            "                                       question_mask  \n",
            "0  The ranger and the rustler both were riding ho...  \n"
          ]
        }
      ],
      "source": [
        "print(training_df.head(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIL4ghJ1MkQx",
        "outputId": "fe68fda3-7e77-49dc-87c1-0ac6afd2f46b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The ranger and the rustler both were riding horses Option 2\n",
            "Tina is racing her two dogs. Her greyhound weighs  Option 1\n",
            "Mike and Sue decide to ride their bikes around the Option 2\n",
            "A tank weighs around 63 tons. A toy car weighs 1.5 Option 2\n",
            "The mammoth moved at a speed of 21 km per hour thr Option 2\n",
            "The mammoth moved at a speed of 18 km per hour thr Option 1\n",
            "Sarah used a remote control to turn on two identic Option 1\n",
            "A sedan weighs 1500 Kg and a garbage truck which w Option 1\n",
            "The beauty queen glided across the marble floors w Option 1\n",
            "Rolling a marble over dirt creates 1.2 mega N resi Option 1\n",
            "Marcus's son took the pool ball off the pool table Option 1\n"
          ]
        }
      ],
      "source": [
        "for index, row in training_df.iterrows():\n",
        "    print(row['input'][:50], row['answer'])\n",
        "    if index == 10:\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPRGEkCGPghj"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary containing model names as keys and their respective pre-trained model identifiers as values\n",
        "test_models = {\n",
        "    'BERT': 'bert-base-uncased',\n",
        "    'RoBERTa': 'roberta-base',\n",
        "    'MathBERT': 'tbs17/MathBERT-custom',\n",
        "    'LinkBERT': 'michiyasunaga/LinkBERT-base',\n",
        "    'FinBERT': 'ProsusAI/finbert',\n",
        "    'ALBERT': 'albert-base-v2',\n",
        "}\n",
        "\n",
        "def get_model(model_name='BERT'):\n",
        "    \"\"\"\n",
        "    Retrieves the tokenizer and model based on the specified model name.\n",
        "\n",
        "    Args:\n",
        "    - model_name: Name of the pre-defined model (default is 'BERT')\n",
        "\n",
        "    Returns:\n",
        "    - tokenizer: AutoTokenizer object initialized with the corresponding pre-trained tokenizer\n",
        "    - model: AutoModelForMaskedLM object initialized with the corresponding pre-trained model\n",
        "    \"\"\"\n",
        "    # Check if the specified model name exists in the test_models dictionary; default to 'BERT' otherwise\n",
        "    if model_name not in test_models:\n",
        "        model_name = 'BERT'\n",
        "\n",
        "    # Initialize the tokenizer with the pre-trained tokenizer for the specified model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(test_models[model_name])\n",
        "\n",
        "    # Initialize the model with the pre-trained model weights for the specified model\n",
        "    model = AutoModelForMaskedLM.from_pretrained(test_models[model_name])\n",
        "\n",
        "    return tokenizer, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmnbW2ZK4MQD"
      },
      "outputs": [],
      "source": [
        "def parse_question(sentence):\n",
        "    \"\"\"\n",
        "    Parses a sentence into segments, separating the question segment from the rest.\n",
        "\n",
        "    Args:\n",
        "    - sentence: The input sentence to be parsed\n",
        "\n",
        "    Returns:\n",
        "    - text_segment: Textual segment of the sentence (excluding the question)\n",
        "    - question_segment: Question segment extracted from the sentence\n",
        "    \"\"\"\n",
        "    segments = sentence.split('.')  # Split the sentence into segments using periods as delimiters\n",
        "    question_segment = segments[-1]  # Extract the last segment as the question segment\n",
        "    text_segment = ''.join(segments[:-1])  # Combine the preceding segments as the text segment\n",
        "    return text_segment, question_segment.strip()  # Return the text segment and the stripped question segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8vmq69C4Vd4"
      },
      "outputs": [],
      "source": [
        "def select_answer(start_scores, end_scores):\n",
        "    # Find the maximum start and end positions\n",
        "    max_start = torch.argmax(start_scores)\n",
        "    max_end = torch.argmax(end_scores)\n",
        "\n",
        "    # Ensure the start position is not greater than the end position\n",
        "    if max_start <= max_end:\n",
        "        return max_start, max_end\n",
        "    else:\n",
        "        # If the start is greater than the end, find the best span within the limits\n",
        "        best_span = (max_start, max_start)  # Initialize with the start position\n",
        "\n",
        "        # Find the best span by maximizing the sum of start and end scores\n",
        "        max_score = start_scores[max_start] + end_scores[max_start]\n",
        "        for end in range(max_start, min(len(end_scores), max_start + 20)):\n",
        "            score = start_scores[max_start] + end_scores[end]\n",
        "            if score > max_score:\n",
        "                max_score = score\n",
        "                best_span = (max_start, end)\n",
        "\n",
        "        return best_span"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0KwpfiRGPUc"
      },
      "outputs": [],
      "source": [
        "def select_answer(start_scores, end_scores):\n",
        "    \"\"\"\n",
        "    Selects the best answer span from given start and end scores.\n",
        "\n",
        "    Args:\n",
        "    - start_scores: Tensor containing scores for the start positions\n",
        "    - end_scores: Tensor containing scores for the end positions\n",
        "\n",
        "    Returns:\n",
        "    - best_span: Tuple containing the start and end positions of the selected answer span\n",
        "    \"\"\"\n",
        "    # Find the position with the maximum score for start and end positions\n",
        "    max_start = torch.argmax(start_scores)\n",
        "    max_end = torch.argmax(end_scores)\n",
        "\n",
        "    # Ensure that the start position is not greater than the end position\n",
        "    if max_start <= max_end:\n",
        "        return max_start, max_end\n",
        "    else:\n",
        "        # If the start is greater than the end, find the best span within the limits\n",
        "        best_span = (max_start, max_start)  # Initialize the best span with the start position\n",
        "\n",
        "        # Find the best span by maximizing the sum of start and end scores within a limit of 20 positions\n",
        "        max_score = start_scores[max_start] + end_scores[max_start]\n",
        "        for end in range(max_start, min(len(end_scores), max_start + 20)):\n",
        "            score = start_scores[max_start] + end_scores[end]\n",
        "            if score > max_score:\n",
        "                max_score = score\n",
        "                best_span = (max_start, end)\n",
        "\n",
        "        return best_span  # Return the tuple containing the best start and end positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_uFUNFF4n3R"
      },
      "source": [
        "## Classification QQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN0clOPP41Nt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import RobertaForQuestionAnswering, RobertaTokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Example input\n",
        "context = \"The ranger and the rustler both were riding horses that galloped at the same speed. \" \\\n",
        "          \"The rustler left at 01:00 where as the ranger left at 0500 hours. \" \\\n",
        "          \"Who has traveled further?? Option 1: the ranger, Option 2: the rustler\"\n",
        "\n",
        "# Example output\n",
        "expected_output = 'Option 2'\n",
        "\n",
        "# Tokenize the input\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "inputs = tokenizer(context, return_tensors=\"pt\")\n",
        "\n",
        "# Create labels (0 for 'Option 1' and 1 for 'Option 2')\n",
        "label = 1 if expected_output == 'Option 2' else 0\n",
        "\n",
        "# Fine-tune RoBERTa for question answering and binary classification\n",
        "model_qa = RobertaForQuestionAnswering.from_pretrained('roberta-base')\n",
        "model_classifier = torch.nn.Linear(model_qa.config.hidden_size, 2)  # Binary classifier layer\n",
        "\n",
        "# Training the binary classifier\n",
        "optimizer = torch.optim.Adam(model_classifier.parameters(), lr=1e-5)\n",
        "\n",
        "# Fine-tuning loop (This is a simplified version and requires proper data preparation and batching for real training)\n",
        "for epoch in range(5):  # 5 epochs for demonstration\n",
        "    optimizer.zero_grad()\n",
        "    qa_output = model_qa(**inputs)\n",
        "    logits = model_classifier(qa_output.pooler_output)  # Use QA output for classification\n",
        "    loss = torch.nn.functional.cross_entropy(logits.view(1, -1), torch.tensor([label]))  # Compute loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Making predictions\n",
        "with torch.no_grad():\n",
        "    qa_output = model_qa(**inputs)\n",
        "    logits = model_classifier(qa_output.pooler_output)\n",
        "    predicted_label = torch.argmax(logits).item()\n",
        "\n",
        "# Mapping predicted label to answer\n",
        "predicted_output = 'Option 2' if predicted_label == 1 else 'Option 1'\n",
        "print(\"Predicted Output:\", predicted_output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "r3kI-rlg0QbZ",
        "0z3hCpRpLRI7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
